
The work on event and entity extraction have several traits that are common with each other and some others that are different. We comment on this by dividing these differences into three high level categories as follows.
\begin{enumerate}
\item \xhdr{Method of event and argument extraction.} Event and argument extraction is performed either independently (in which choice of an event-entity relation does not affect any others) or jointly (where events and its arguments are extracted jointly). The work by \citeauthor{bjorne} performs event extraction by a pipeline of three independent steps of identifying triggers first, followed by argument extraction and then semantic prost processing. This method  is prone to cascading errors introduced in early stages of the pipeline. For instance, if a trigger is missed in the first stage, we will never be able to extract the full event that it results in. Even though this can be tackled by passing several additional candidate to the next stage, this will increase the false positive rate as highlighted by \cite{miwa2010c}. In addition, these models cannot make use of the rich set of features by looking at how different events and entities interact with each other. Also, the different rule based post-processing steps that need to be used to clean up the event-entity combinations extracted might lead to partially correct relations to be thrown out because of errors introduced in some stage of the pipeline. In short, joint models helps to capture the dependencies better and are more robust. If we look at joint event extraction, there are two common ways in which it is done - by means of semantic role labeling or as a structure prediction problem. \citeauthor{toutanova} approaches the problem as a semantic role labeling task while \citeauthor{bjorne} and \citeauthor{riedelmc} solves it as a structure prediction task

\item \xhdr{Representation of events and entities} Trees and graphs are two popular structures used to represent events and entities. Both \citeauthor{bjorne} and \citeauthor{riedelmc} use graph structures to encode the event-entity and event-event relationships, although in different ways. In the former, event extraction is done disjointly for edge prediction. The latter uses graphs to generate binary variables as edges denoting entity-entity relationships and solves the problem of event extraction as an optimization problem over binary variables. \citeauthor{riedelmc} and \citeauthor{mcclosky} use the parse tree structure quite extensively. For instance, \citeauthor{riedelmc} maps the features from the parse tree directly into vector space. While using parse structures that encode syntax information helps to include important features (relating to grouping and hierarchy of words), working with graph structures appears to be easier to approach as a learning problem.

\item \xhdr{Solution} \citeauthor{riedelmc} approaches the task as an optimization problem over binary variables, while \citeauthor{bjorne} uses multiclass SVM classifier for this task. Some others use re-ranking approaches \cite{toutanova} built on a bottom-up fashion. While, it is not obvious which of these methods works best, each seem to have its on advantages. For instance, a re-ranking dynamic programming approach works well with a tree representation, while a multiclass classifier works well with graph structures.

\item \xhdr{Use of local and global features} Most of the papers use global features for entity extraction as event arguments often have dependencies between each other. While some are in the form of post processing rules to ensure consistency, some encode it into the structure of the problem itself, which is easier to optimize.

\end{enumerate}