\section{Joint Model for Process Extraction}

Our task is given a paragraph $\bx$ and a set of event mention triggers $\sT$, to extract all event-event relations $E$. Similar to Do et al. \shortcite{Do12} our model consists of two parts. In section \ref{subsec:pairwise}, we use a local pairwise classifier that considers each pair of triggers, and then in Section \ref{subsec:global} we incorporate global constraints in an ILP formulation.

\subsection{Local pairwise classifier} \label{subsec:pairwise}

The pairwise classifier predicts relations between all event mention pairs (represented only by their triggers). Since relations in $\sR$ are directed, we must predict also the direction of each relation. We do this by expanding $\sR$ to include reverse relations and so we re-define $\sR$ to include 11 relations: \textsc{NextEvent}, \textsc{PreviousEvent}, \textsc{Cotemporal}, \textsc{SuperEvent}, \textsc{SubEvent}, \textsc{Causes}, \textsc{Caused}, \textsc{Enables}, \textsc{Enabled}, \textsc{SameEvent}, \textsc{None}, where \textsc{None} indicates no relation. Thus, our classifier is a function $w:\sT \times \sT \rightarrow \sR$. Let $n$ be the number of event triggers in a process description, and $t_i$ be the i'th trigger appearing in the description, since $w(t_i,t_j)$ completely determines $w(t_j,t_i)$ it suffices to consider only pairs such that $i<j$.

We have constructed an initial set of features based on previous work in temporal ordering \cite{Chambers08,Do12}. However, since our training set is quite small and we consider a larger set of relations we have defined some novel features that improved performance (see Section~\ref{sec:experiment}. We note that contrary to work in BioNLP, we did not employ any biological dictionaries.

\paragraph{Baseline features\footnote{Some features from \cite{Chambers08,Do12} were not included since they did not improve performance on the development set.}}

\begin{itemize}
\item lemma pairs including WordNet normalization to verbs, POS paris
\item for consecutive event mentions - words between
\item for consecutive event mentions - temporal connectives
\item POS pair
\item quantized num of sentences and words
\item lowest common ancestor
\item one dominates the other
\item share child
\end{itemize}

\paragraph{Novel features}

\begin{itemize}
\item for consecutive event mentions - clusterings
\item existence of and (not important)
\item - first and nominalization - for SuperEvent
\item - same lemma - for SameEvent (includes nominialization)
\item determiner before the second event - for SameEvent
\item dependency path between them
\item syntactic marker features including clustering
\end{itemize}

Talk about the fact that it is important to have the clustering and syntactic features to share stats.


\subsection{Global Constraints} \label{subsec:global}

[I think we should have a short experiment with soft constraints on the degree of nodes, I think this will add some substance even if our intuition is that it might not work I don't think it is a lot of work]

Motivation paragraph - naturally there are cases where local decision can lead to global structures that don't make sense. Give examples - one for something that is a hard constraint and something for soft constraints. Maybe we should have a figure with examples for bad local predictions - connectivity and triads.

Define the notations for formulating the objective function and formulate the objective function (variables are indicators $e_{ijr}$). Our formulation will probably have in the objective the local model scores and the soft constraints. Our hard constraints are those to make the formulation make sense and the hard constraints. Say that we use log probabilities from the pairwise classifier as our weights in the model.

Then we describe the modeling constraints. 

Connectivity - short explanation. and then show the formulation which is a slight variation on \cite{Martins09}. Refer to the motivating figure. 

chain-like - we did not implement this because we didn't think it would help but I think it is easy to formulate and experiment with this. Explain the motivation. Refer to the table that shows that the local classifier is doing already pretty well and say that later we show whether this helps or not in the process of choosing soft constraints.

Triads - some triangles are not meaningful. To better understand what things are predicted by the model but are not in the gold and vice versa we counted and compared. Table... shows the top K of these. These guided us to engineer constraints that will improve the local classifier 

Now we go over each one of the triad constraints we experimented with (even if some got 0 weight at the end) We explain the motivation and show the hard constraint formulation mentioning that turning them into soft is easy. We have to not make this boring so try to explain with examples.

Say something about the number of variables and constraints. Say that we use Gurobi ILP solver. Say that in principle one can use dual decomposition methods but in practice for this work we found ILP was fast enough.

Tuning of the soft constraints parameters - should we talk about this here or in the experimental section - probably in the experimental setting part



