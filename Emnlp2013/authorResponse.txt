First, we would like to thank the reviewers for their constructive feedback
and useful suggestions.

If the paper is accepted, we will clarify all points raised
by the reviewers as unclear.

Reviewer 1
1. Triggers stand for event mentions and can be co-referent. For example, in
Figure 1 the trigger "spin" in sentence 3 is co-referent with the trigger
"Turning" in sentence 4, as denoted by the "same" relation.
2. Regarding event extraction - we have implemented some simple systems that
extract the triggers and performance is in the low 70's. We have focused on
event-event relations in this paper but combining the systems is simple and as
the reviewer points would result in a decrease in performance compared to
using gold standard triggers.
3. We agree that adding average precision/recall across processes is
interesting. This score should be higher since the weight for simple processes will be equal to the weight of
complex processes.
4. We will elaborate on relation sets used in temporal reasoning. Allen, 1983,
had 13 temporal relations and most past work used a coarser relation set.
Reducing the number of relations simplifies annotation and learning and
we chose a minimal set that we found expressive enough to model relations in
processes.
5. We can add more concrete suggestions for improving the local classifier, e.g., using
background knowledge about the typical order of triggers ("opening" usually
happens before "entering") to improve local predictions. This background knowledge can be obtained in an unsupervised
manner using narrative chain methods (Chambers et al.) or
Frame Induction methods (Cheung et al.). Another idea is to use external
corpora e.g. given a process description find text on Wikipedia that seems to describe the
same process to improve local predictions. In general our current method uses
very little data and we believe using large amounts of text with no
supervision should improve local predictions.

Reviewer 2
1. We can provide some examples for features that did not yield improvement
on the dev and were therefore omitted (e.g., Wordnet synonyms). We note
that Table Table 3 describes exactly the set of features used by local_base.
2. We will add the 30 connectives, and also plan to release the code with the
data which should allow for complete reproducibility.
3. In some cases parsing errors result in errors related to the syntactic
features that rely on a correct parse, as described in Section 3.2.
However, we found this is not a major cause of error.
4. We will provide more details on data selection. In general, annotators were
given a chapter in the "Biology" book, read the chapter and marked processes.
In general, processes come from the body of the chapter rather than the
overview (since this is a textbook there is no "method" section usually).

Reviewer 3
The units used in re-sampling are the relation prediction for each pair of
events.
