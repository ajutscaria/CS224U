In this section, we present the models we developed. We combine the different approaches adopted in prior literature to build a model that can be used for event and entity extraction not specific to any domain. We demonstrate this by testing our models on the general dataset, the results of which are presented in the next section. Our system takes a paragraph of text as input and does the following tasks:

\begin{enumerate}
\item Identify the events by locating the trigger words.
\item For each event, identify entities that are its arguments.
\item Assign semantic roles like Result, Agent, Theme, Location etc. to event-entity pairs identified.
\end{enumerate}

We model events and entities as sub-trees headed by a node in the constituency tree. Each sentence is assumed to be independent of each other as far as event-entity relationships are concerned. Events are denoted by their trigger words and are hence pre-terminals in the parse tree. Entities are denoted by a parse tree-node covering a sub-tree that spans over the whole text of the entity. In some cases, there is no single node that covers the entire entity (mostly because of parser errors, for e.g., PP attachment). In this case, we use an approximation to mark entities, by first repeatedly removing tokens from the end of the span to find a single subtree that covers the full text, otherwise, we repeat the same process from the beginning of the span of text. We manually verified that this heuristic works well in practice and results in entities that convey almost the full meaning of original span, and are well-formed.

In our project, we use Stanford Core NLP tools. We use the annotation pipeline available in the toolkit including tokenization, lemmatization, dependency and constituency parsers, and POS taggers. The events, entities and their relationships are represented as annotations on the already existing sentence annotations, by implementing the CoreAnnotation interface. This helps us to integrate our codebase with the existing features of the CoreNLP toolkit.

For all the classification tasks described in this paper, we use maximum entropy model based on an implementation of L-BFGS for Quasi Newton unconstrained minimization. We use features based on the dependency graph of the sentence in conjunction with the constituency parse, since it contains information about the dependencies between tokens, which are critical in identifying event-entity relations. The features are extracted by identifying the position of the headword of an entity or event from the dependency tree and analyzing the properties of the head word. We use Collins head finding algorithm for finding the head word of a parse tree node. 

First, we present our model for task 1 which is an independent classification task. Then, we talk about task 2 where we identify entities that are arguments to event triggers. Since the information about entities can be used to improve event trigger prediction, we then cover the iterative optimization algorithm we developed that iteratively predicts event triggers from entities and entities from event triggers. Then, we talk about the joint re-ranking model we developed for semantic role labeling.