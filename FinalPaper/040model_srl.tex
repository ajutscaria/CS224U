\subsection{Semantic Role Labeling}
For argument identification, we had used a binary classifier based on MaxEnt model that predicts a probability value for it to be an argument. For semantic role labeling, we extended this model to a multi-class classifier to generate probability values for a parse-tree node being assigned to a specific semantic role. We also modified the dynamic program for non-overlapping constraint used in argument prediction to a re-ranking model that jointly assigns semantic role to all nodes in a sub-tree. Let $L$ be a labeling of semantic roles to the parse tree nodes, including $NONE$ if it is not an entity. Our goal is to maximize the probability of the labeling we generate.

We use a bottom up re-ranking approach by keeping the top-k joint assignment of semantic roles to all nodes in a sub-tree. This algorithm is similar to the dynamic programming for non-overlapping constraints. At the pre-terminal nodes, we keep just the semantic roles of the word subsumsed by the node in descending order of probability. At nodes above the pre-terminal nodes, there are two scenarios:

\begin{enumerate}
\item The node is an argument to the trigger: In this case, the node has a non-NONE semantic role and none of the children nodes can be entities and hence all children would have semantic role $NONE$. For each non-NONE semantic role of the node, we compute the probability value of the joint labeling of the sub-tree.
\item The node is not an argument to the trigger: In this case, the node has a semantic role of $NONE$. Since at each of the child nodes we have top-k possible assignments, we take all combinations of assignments of children nodes and compute the probability for each of these possible joint labeling.
\end{enumerate}

The next step is to re-rank these possible joint assignments at the node and then retain only the top-k at the node. This algorithm proceeds until we reach the root and the joint labeling that has the highest probability will be the semantic roles predicted by the model. We are currently using k=5 in our model.