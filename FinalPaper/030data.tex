In this project, the dataset was prepared by annotating 125 paragraphs from different chapters of the text book {\em Biology (Eighth Edition)} by {\em Neil A. Campbell} and {\em Jane B. Reece}. Each paragraph is a text file and has an associated annotation file that indicates the different events and entities (by their character offsets in the original paragraph) and the event-entity and event-event relationships. The annotations were done by experts in the field (employees of the company Vulcan). Since there is not much data at our disposal, we split the data by a proportion of 70-30\% for training and testing. We randomly permute the order of files to avoid similarities in adjacent files and then use 10 fold cross validation on the training set. 

For event prediction, we use F1 score based on the trigger predictions made. In entity prediction, the F1 score is based on whether an entity was predicted correctly along with its association with the corresponding event. In addition, our evaluation of the entity prediction model is very conservative as we consider only an exact match with the whole text of the entity to be a correct prediction. Entities typically span many words and the text chosen to represent an entity is subjective. For instance, the question whether 'plants in our original population' or 'plants' is to be marked as an entity does not have a clear answer. For semantic role labeling, we measure the F1 score based on the role predicted for entity-event pairs.

To test if the models and algorithms we developed generalize to text content on the web, we built a general dataset containing 5 paragraphs. We included data from Wikipedia articles, New York Times news headlines and news articles. The articles and headlines were chosen to cover main topics like general news, politics, world news and sports. We manually annotated the data for event triggers and entities that were its arguments.